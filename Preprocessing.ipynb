{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684ba6a3-ae43-4e75-a376-4c6ced3becd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emotion_lexicon_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/Emotion_Lexicon.csv\"\n",
    "essays_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/essays_utf8.csv\"\n",
    "mairesse_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/mairesse.csv\"\n",
    "mbti_1_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/mbti_1.csv\"\n",
    "\n",
    "emotion_lexicon_df = pd.read_csv(emotion_lexicon_path)\n",
    "essays_df = pd.read_csv(essays_path)\n",
    "mairesse_df = pd.read_csv(mairesse_path, header=None)\n",
    "mbti_1_df = pd.read_csv(mbti_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b16a66e-b485-4eeb-8edd-a951075361cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           #AUTHID                                               TEXT cEXT  \\\n",
      "0  1997_012113.txt  The lights  are all out here in Hardin House. ...    y   \n",
      "1  1997_012750.txt  I have watching Comedy Central for the past ho...    y   \n",
      "2  1997_030596.txt  Well, I figured I should write this right now ...    y   \n",
      "3  1997_033283.txt  I don't like having to write an my couch. I ne...    y   \n",
      "4  1997_053414.txt  This blank screen is staring at me and my fing...    y   \n",
      "\n",
      "  cNEU cAGR cCON cOPN       mairesse_0  mairesse_1  mairesse_2  ...  \\\n",
      "0    n    y    y    n  1997_012113.txt   -0.906225   -0.282501  ...   \n",
      "1    n    n    n    y  1997_012750.txt   -0.493431   -1.352080  ...   \n",
      "2    y    y    y    y  1997_030596.txt    1.118787   -0.338031  ...   \n",
      "3    n    y    n    y  1997_033283.txt   -0.527438    0.542460  ...   \n",
      "4    n    y    y    y  1997_053414.txt    0.122799    0.596609  ...   \n",
      "\n",
      "   mairesse_75  mairesse_76  mairesse_77  mairesse_78  mairesse_79  \\\n",
      "0    -0.422267     0.744863    -0.451544     0.133300     0.226499   \n",
      "1    -0.422267     1.331875    -0.451544     0.290709     1.113311   \n",
      "2    -0.422267    -0.452623    -0.451544    -0.408772    -0.005531   \n",
      "3    -0.422267    -1.028267    -0.451544    -0.408772    -0.548258   \n",
      "4    -0.422267     0.513222    -0.451544     1.416726     0.420822   \n",
      "\n",
      "   mairesse_80  mairesse_81  mairesse_82  mairesse_83  mairesse_84  \n",
      "0     4.618658     3.369903     5.000089     4.670976     4.714842  \n",
      "1     5.259377     3.070537     4.802325     4.679371     5.168178  \n",
      "2     5.033048     4.486362     4.696222     5.128474     4.487069  \n",
      "3     4.717551     4.945683     4.712785     4.988888     4.397205  \n",
      "4     4.983241     3.990245     4.710706     4.786429     5.008889  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "Merged DataFrame saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming essays_df and mairesse_df are already loaded as Pandas DataFrames\n",
    "\n",
    "# Set the first row of mairesse_df as the column headers\n",
    "mairesse_df.columns = [f\"mairesse_{i}\" for i in range(mairesse_df.shape[1])]\n",
    "mairesse_df = mairesse_df[1:]\n",
    "\n",
    "# Convert `#AUTHID` and the corresponding column in mairesse_df to string type for accurate sorting\n",
    "essays_df['#AUTHID'] = essays_df['#AUTHID'].astype(str)\n",
    "mairesse_df[mairesse_df.columns[0]] = mairesse_df[mairesse_df.columns[0]].astype(str)\n",
    "\n",
    "# Sort both DataFrames\n",
    "essays_df.sort_values(by=\"#AUTHID\", inplace=True)\n",
    "mairesse_df.sort_values(by=\"mairesse_0\", inplace=True)\n",
    "\n",
    "# Merge DataFrames\n",
    "essays_mairesse_df = pd.merge(essays_df, mairesse_df, left_on=\"#AUTHID\", right_on=\"mairesse_0\", how='inner')\n",
    "\n",
    "# Specify the path where you want to save the merged DataFrame\n",
    "save_path = '/home/vincent/AAA_projects/MVCS/DigitalHuman/data/merged_data.csv'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "essays_mairesse_df.to_csv(save_path, index=False)\n",
    "print(essays_mairesse_df.head())\n",
    "print(\"Merged DataFrame saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55407fd-9e72-402a-9984-88d78949e299",
   "metadata": {},
   "source": [
    "# Correlations between Neuroticism, Extraversion, Openness, Agreeableness, Conscientiousness, -to- Sense of coherence, Balance, Comprehensibility, Manageability, Meaningfulness, Reflection \n",
    "(https://journals.sagepub.com/doi/10.1177/1359105319884597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c614cc1-a433-4d0e-861e-5a27a84690d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrait\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_effect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg_effect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI_r\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI_g\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mτ2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Loop through the nested dictionary\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, traits \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trait, values \u001b[38;5;129;01min\u001b[39;00m traits\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Create a list consisting of the category, trait, and various metrics\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         row \u001b[38;5;241m=\u001b[39m [category, trait]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open('psych_traits_digital_human_dict.csv', 'w', newline='') as f:\n",
    "    # Create a CSV writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow(['Category', 'Trait', 'r_effect', 'g_effect', 'CI_r', 'CI_g', 'k', 'Q', 'I2', 'τ2'])\n",
    "\n",
    "    # Loop through the nested dictionary\n",
    "    for category, traits in data.items():\n",
    "        for trait, values in traits.items():\n",
    "            # Create a list consisting of the category, trait, and various metrics\n",
    "            row = [category, trait]\n",
    "            for metric, value in values.items():\n",
    "                row.append(value)\n",
    "\n",
    "            # Write the row to the CSV\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee89b073-14b9-4177-be82-2192492449a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite features for Sense of coherence:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.905\n",
      "    - k: 21\n",
      "    - Q: 369.75\n",
      "    - I2: 94.59\n",
      "    - τ2: 0.03\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.41000000000000003\n",
      "    - k: 17\n",
      "    - Q: 119.87\n",
      "    - I2: 86.65\n",
      "    - τ2: 0.01\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.2\n",
      "    - k: 12\n",
      "    - Q: 45.62\n",
      "    - I2: 75.89\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.43\n",
      "    - k: 11\n",
      "    - Q: 23.35\n",
      "    - I2: 57.16\n",
      "    - τ2: 0.0\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.475\n",
      "    - k: 12\n",
      "    - Q: 62.27\n",
      "    - I2: 82.34\n",
      "    - τ2: 0.01\n",
      "\n",
      "Composite features for Balance:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.095\n",
      "    - k: 2\n",
      "    - Q: 3.52\n",
      "    - I2: 70.17\n",
      "    - τ2: 0.01\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.07500000000000001\n",
      "    - k: 2\n",
      "    - Q: 0.06\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.10500000000000001\n",
      "    - k: 2\n",
      "    - Q: 0.06\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.07500000000000001\n",
      "    - k: 2\n",
      "    - Q: 0.73\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.06\n",
      "    - k: 2\n",
      "    - Q: 0.24\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "\n",
      "Composite features for Comprehensibility:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.825\n",
      "    - k: 2\n",
      "    - Q: 2.28\n",
      "    - I2: 56.18\n",
      "    - τ2: 0.0\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.5\n",
      "    - k: 2\n",
      "    - Q: 1.92\n",
      "    - I2: 47.9\n",
      "    - τ2: 0.0\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.34500000000000003\n",
      "    - k: 2\n",
      "    - Q: 0.19\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.26\n",
      "    - k: 2\n",
      "    - Q: 0.75\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.425\n",
      "    - k: 2\n",
      "    - Q: 2.24\n",
      "    - I2: 55.41\n",
      "    - τ2: 0.0\n",
      "\n",
      "Composite features for Manageability:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.725\n",
      "    - k: 4\n",
      "    - Q: 20.33\n",
      "    - I2: 85.24\n",
      "    - τ2: 0.02\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.425\n",
      "    - k: 4\n",
      "    - Q: 3.11\n",
      "    - I2: 3.46\n",
      "    - τ2: 0.0\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.275\n",
      "    - k: 4\n",
      "    - Q: 2.8\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.41000000000000003\n",
      "    - k: 4\n",
      "    - Q: 12.49\n",
      "    - I2: 75.99\n",
      "    - τ2: 0.01\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.265\n",
      "    - k: 4\n",
      "    - Q: 6.1\n",
      "    - I2: 50.84\n",
      "    - τ2: 0.0\n",
      "\n",
      "Composite features for Meaningfulness:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.535\n",
      "    - k: 2\n",
      "    - Q: 4.98\n",
      "    - I2: 79.92\n",
      "    - τ2: 0.01\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.475\n",
      "    - k: 2\n",
      "    - Q: 0.22\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.45999999999999996\n",
      "    - k: 2\n",
      "    - Q: 0.21\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.41000000000000003\n",
      "    - k: 2\n",
      "    - Q: 0.21\n",
      "    - I2: 0\n",
      "    - τ2: 0.01\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.425\n",
      "    - k: 2\n",
      "    - Q: 0.28\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "\n",
      "Composite features for Reflection:\n",
      "  - Neuroticism:\n",
      "    - Composite Feature: -0.86\n",
      "    - k: 3\n",
      "    - Q: 7.32\n",
      "    - I2: 72.14\n",
      "    - τ2: 0.02\n",
      "  - Extraversion:\n",
      "    - Composite Feature: 0.6\n",
      "    - k: 3\n",
      "    - Q: 1.08\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Openness:\n",
      "    - Composite Feature: 0.67\n",
      "    - k: 3\n",
      "    - Q: 0.43\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Agreeableness:\n",
      "    - Composite Feature: 0.22499999999999998\n",
      "    - k: 3\n",
      "    - Q: 1.99\n",
      "    - I2: 0\n",
      "    - τ2: 0.0\n",
      "  - Conscientiousness:\n",
      "    - Composite Feature: 0.505\n",
      "    - k: 3\n",
      "    - Q: 3.11\n",
      "    - I2: 35.92\n",
      "    - τ2: 0.01\n",
      "\n",
      "Composite features for Sense of coherence:\n",
      "  - Neuroticism: -0.905\n",
      "  - Extraversion: 0.41000000000000003\n",
      "  - Openness: 0.2\n",
      "  - Agreeableness: 0.43\n",
      "  - Conscientiousness: 0.475\n",
      "\n",
      "Composite features for Balance:\n",
      "  - Neuroticism: -0.095\n",
      "  - Extraversion: 0.07500000000000001\n",
      "  - Openness: 0.10500000000000001\n",
      "  - Agreeableness: 0.07500000000000001\n",
      "  - Conscientiousness: 0.06\n",
      "\n",
      "Composite features for Comprehensibility:\n",
      "  - Neuroticism: -0.825\n",
      "  - Extraversion: 0.5\n",
      "  - Openness: 0.34500000000000003\n",
      "  - Agreeableness: 0.26\n",
      "  - Conscientiousness: 0.425\n",
      "\n",
      "Composite features for Manageability:\n",
      "  - Neuroticism: -0.725\n",
      "  - Extraversion: 0.425\n",
      "  - Openness: 0.275\n",
      "  - Agreeableness: 0.41000000000000003\n",
      "  - Conscientiousness: 0.265\n",
      "\n",
      "Composite features for Meaningfulness:\n",
      "  - Neuroticism: -0.535\n",
      "  - Extraversion: 0.475\n",
      "  - Openness: 0.45999999999999996\n",
      "  - Agreeableness: 0.41000000000000003\n",
      "  - Conscientiousness: 0.425\n",
      "\n",
      "Composite features for Reflection:\n",
      "  - Neuroticism: -0.86\n",
      "  - Extraversion: 0.6\n",
      "  - Openness: 0.67\n",
      "  - Agreeableness: 0.22499999999999998\n",
      "  - Conscientiousness: 0.505\n",
      "\n",
      "CSV file 'composite_features.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Weights for r and g based on their perceived importance\n",
    "weights = {'r_effect': 0.5, 'g_effect': 0.5}\n",
    "\n",
    "# Researched traits (in your case, these are the big five personality traits)\n",
    "researched_traits = [\"Neuroticism\", \"Extraversion\", \"Openness\", \"Agreeableness\", \"Conscientiousness\"]\n",
    "\n",
    "# Create an empty dictionary to store the composite features\n",
    "composite_features = {}\n",
    "\n",
    "# Calculate the composite features\n",
    "for psychological_construct, values in data.items():\n",
    "    composite_features[psychological_construct] = {}\n",
    "    for researched_trait in researched_traits:\n",
    "        val = values.get(researched_trait)\n",
    "        if val is not None:\n",
    "            r = val['r_effect']\n",
    "            g = val['g_effect']\n",
    "            k = val['k']\n",
    "            Q = val['Q']\n",
    "            I2 = val['I2']\n",
    "            τ2 = val['τ2']\n",
    "            \n",
    "            composite_feature = weights['r_effect'] * r + weights['g_effect'] * g\n",
    "            # Store composite feature along with k, Q, I2, τ2\n",
    "            composite_features[psychological_construct][researched_trait] = {\n",
    "                'composite_feature': composite_feature,\n",
    "                'k': k,\n",
    "                'Q': Q,\n",
    "                'I2': I2,\n",
    "                'τ2': τ2\n",
    "            }\n",
    "\n",
    "# Display the composite features along with k, Q, I2, τ2\n",
    "for psychological_construct, traits in composite_features.items():\n",
    "    print(f\"Composite features for {psychological_construct}:\")\n",
    "    for researched_trait, metrics in traits.items():\n",
    "        print(f\"  - {researched_trait}:\")\n",
    "        print(f\"    - Composite Feature: {metrics['composite_feature']}\")\n",
    "        print(f\"    - k: {metrics['k']}\")\n",
    "        print(f\"    - Q: {metrics['Q']}\")\n",
    "        print(f\"    - I2: {metrics['I2']}\")\n",
    "        print(f\"    - τ2: {metrics['τ2']}\")\n",
    "    print()\n",
    "\n",
    "# Display the composite features alone (without k, Q, I2, τ2)\n",
    "for psychological_construct, traits in composite_features.items():\n",
    "    print(f\"Composite features for {psychological_construct}:\")\n",
    "    for researched_trait, metrics in traits.items():\n",
    "        composite_feature = metrics['composite_feature']\n",
    "        print(f\"  - {researched_trait}: {composite_feature}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7ccf6d-d23c-47b4-afb0-368a3106e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/composite_features.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the file name for the CSV\n",
    "csv_file_name = \"composite_features.csv\"\n",
    "\n",
    "# Specify the target directory\n",
    "target_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data\"\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_file_path = os.path.join(target_directory, csv_file_name)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    # Define the CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    header = [\"Psychological Construct\", \"Researched Trait\", \"Composite Feature\", \"k\", \"Q\", \"I2\", \"τ2\"]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Write the data rows\n",
    "    for psychological_construct, traits in composite_features.items():\n",
    "        for researched_trait, metrics in traits.items():\n",
    "            row = [\n",
    "                psychological_construct,\n",
    "                researched_trait,\n",
    "                metrics['composite_feature'],\n",
    "                metrics['k'],\n",
    "                metrics['Q'],\n",
    "                metrics['I2'],\n",
    "                metrics['τ2']\n",
    "            ]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72f6d3-ffb8-4b93-9e3d-f10a88b69934",
   "metadata": {},
   "source": [
    "# Sub-Attribute Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0388089-de11-4332-9f66-eb74c48a4eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Attribute Weights for Sense of coherence:\n",
      "  - Neuroticism: 57.795\n",
      "  - Extraversion: 51.825\n",
      "  - Openness: 43.945\n",
      "  - Agreeableness: 34.08\n",
      "  - Conscientiousness: 47.17\n",
      "Sub-Attribute Weights for Balance:\n",
      "  - Neuroticism: 36.085\n",
      "  - Extraversion: 1.0\n",
      "  - Openness: 1.0\n",
      "  - Agreeableness: 1.0\n",
      "  - Conscientiousness: 1.0\n",
      "Sub-Attribute Weights for Comprehensibility:\n",
      "  - Neuroticism: 29.09\n",
      "  - Extraversion: 24.95\n",
      "  - Openness: 1.0\n",
      "  - Agreeableness: 1.0\n",
      "  - Conscientiousness: 28.705\n",
      "Sub-Attribute Weights for Manageability:\n",
      "  - Neuroticism: 44.62\n",
      "  - Extraversion: 3.73\n",
      "  - Openness: 2.0\n",
      "  - Agreeableness: 39.995\n",
      "  - Conscientiousness: 27.42\n",
      "Sub-Attribute Weights for Meaningfulness:\n",
      "  - Neuroticism: 40.96\n",
      "  - Extraversion: 1.0\n",
      "  - Openness: 1.0\n",
      "  - Agreeableness: 1.0\n",
      "  - Conscientiousness: 1.0\n",
      "Sub-Attribute Weights for Reflection:\n",
      "  - Neuroticism: 37.57\n",
      "  - Extraversion: 1.5\n",
      "  - Openness: 1.5\n",
      "  - Agreeableness: 1.5\n",
      "  - Conscientiousness: 19.46\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store the Sub-Attribute Weights\n",
    "sub_attribute_weights = {}\n",
    "\n",
    "# Calculate the Sub-Attribute Weights\n",
    "for psychological_construct, traits in composite_features.items():\n",
    "    sub_attribute_weights[psychological_construct] = {}\n",
    "    for researched_trait, metrics in traits.items():\n",
    "        \n",
    "        # Fetch k and I2 values\n",
    "        k = metrics['k']\n",
    "        I2 = metrics['I2']\n",
    "        \n",
    "        # Normalize k and I2 (This is a simple example; you'll actually need to find min and max across all traits)\n",
    "        # normalized_k = (k - min_k) / (max_k - min_k)\n",
    "        # normalized_I2 = (I2 - min_I2) / (max_I2 - min_I2)\n",
    "        \n",
    "        # For this example, we'll assume that k and I2 are already in a normalized form (between 0 and 1)\n",
    "        \n",
    "        # Calculate Sub-Attribute Weight as an average of k and I2\n",
    "        sub_attribute_weight = (k + I2) / 2\n",
    "        \n",
    "        # Store Sub-Attribute Weight\n",
    "        sub_attribute_weights[psychological_construct][researched_trait] = sub_attribute_weight\n",
    "\n",
    "# Display the Sub-Attribute Weights\n",
    "for psychological_construct, traits in sub_attribute_weights.items():\n",
    "    print(f\"Sub-Attribute Weights for {psychological_construct}:\")\n",
    "    for researched_trait, weight in traits.items():\n",
    "        print(f\"  - {researched_trait}: {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc2edfb5-eebb-414d-b76d-fcae7ca1d22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/sub_attribute_weights.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the file name for the CSV\n",
    "csv_file_name_sub_attr_weights = \"sub_attribute_weights.csv\"\n",
    "\n",
    "# Specify the target directory (same directory as the previous CSV)\n",
    "target_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data\"\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_file_path_sub_attr_weights = os.path.join(target_directory, csv_file_name_sub_attr_weights)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path_sub_attr_weights, mode='w', newline='') as csv_file:\n",
    "    # Define the CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    header = [\"Psychological Construct\", \"Researched Trait\", \"Sub-Attribute Weight\"]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Write the data rows\n",
    "    for psychological_construct, traits in sub_attribute_weights.items():\n",
    "        for researched_trait, weight in traits.items():\n",
    "            row = [\n",
    "                psychological_construct,\n",
    "                researched_trait,\n",
    "                weight\n",
    "            ]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path_sub_attr_weights}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894e214b-04c9-44a8-a653-65373cf8a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite-Trait Score for Sense of coherence: 14.792924999999997\n",
      "Composite-Trait Score for Balance: -3.113075\n",
      "Composite-Trait Score for Comprehensibility: 1.2803749999999994\n",
      "Composite-Trait Score for Manageability: -6.549999999999997\n",
      "Composite-Trait Score for Meaningfulness: -20.1436\n",
      "Composite-Trait Score for Reflection: -20.240400000000005\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store the Composite-Trait Scores\n",
    "composite_trait_scores = {}\n",
    "\n",
    "# Calculate the Composite-Trait Scores\n",
    "for psychological_construct in composite_features.keys():\n",
    "    composite_trait_score = 0  # Initialize to zero for each psychological construct\n",
    "    \n",
    "    for researched_trait in composite_features[psychological_construct].keys():\n",
    "        # Fetch Composite Feature and Sub-Attribute Weight\n",
    "        composite_feature = composite_features[psychological_construct][researched_trait]['composite_feature']\n",
    "        sub_attribute_weight = sub_attribute_weights[psychological_construct][researched_trait]\n",
    "        \n",
    "        # Calculate the component of the Composite-Trait Score related to this researched trait\n",
    "        composite_trait_score += composite_feature * sub_attribute_weight\n",
    "    \n",
    "    # Store the Composite-Trait Score for the psychological construct\n",
    "    composite_trait_scores[psychological_construct] = composite_trait_score\n",
    "\n",
    "# Display the Composite-Trait Scores\n",
    "for psychological_construct, score in composite_trait_scores.items():\n",
    "    print(f\"Composite-Trait Score for {psychological_construct}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3c91a1-9d58-4275-95f0-a25dfca14d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/composite_trait_scores.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the file name for the CSV\n",
    "csv_file_name_comp_trait_scores = \"composite_trait_scores.csv\"\n",
    "\n",
    "# Specify the target directory (same directory as the previous CSV)\n",
    "target_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data\"\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_file_path_comp_trait_scores = os.path.join(target_directory, csv_file_name_comp_trait_scores)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path_comp_trait_scores, mode='w', newline='') as csv_file:\n",
    "    # Define the CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    header = [\"Psychological Construct\", \"Composite-Trait Score\"]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Write the data rows\n",
    "    for psychological_construct, score in composite_trait_scores.items():\n",
    "        row = [\n",
    "            psychological_construct,\n",
    "            score\n",
    "        ]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path_comp_trait_scores}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9038e344-da6f-409a-8c11-87859ab09df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Score for Sense of coherence: 1.6737618528160483\n",
      "Adjusted Score for Balance: 0.20859166566826876\n",
      "Adjusted Score for Comprehensibility: 0.5680885917670295\n",
      "Adjusted Score for Manageability: -0.07263697531591971\n",
      "Adjusted Score for Meaningfulness: -1.1849422057421488\n",
      "Adjusted Score for Reflection: -1.1928629291932777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Calculate the mean and standard deviation for the composite-trait scores\n",
    "mean_score = np.mean(list(composite_trait_scores.values()))\n",
    "std_deviation = np.std(list(composite_trait_scores.values()))\n",
    "\n",
    "# Calculate the Adjusted Scores\n",
    "adjusted_scores = {}\n",
    "for construct, score in composite_trait_scores.items():\n",
    "    adjusted_scores[construct] = (score - mean_score) / std_deviation\n",
    "\n",
    "# Display the Adjusted Scores\n",
    "for construct, score in adjusted_scores.items():\n",
    "    print(f\"Adjusted Score for {construct}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80666fae-11fb-479c-ba74-b244177f8c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7074bef-8257-4c98-ae5d-8300be59a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/adjusted_scores.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the file name for the CSV\n",
    "csv_file_name_adjusted_scores = \"adjusted_scores.csv\"\n",
    "\n",
    "# Specify the target directory (same directory as the previous CSV)\n",
    "target_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data\"\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_file_path_adjusted_scores = os.path.join(target_directory, csv_file_name_adjusted_scores)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path_adjusted_scores, mode='w', newline='') as csv_file:\n",
    "    # Define the CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    header = [\"Psychological Construct\", \"Adjusted Score\"]\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Write the data rows\n",
    "    for construct, score in adjusted_scores.items():\n",
    "        row = [\n",
    "            construct,\n",
    "            score\n",
    "        ]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path_adjusted_scores}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8614b633-42dd-4821-b484-bb195eef8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths for the DataFrames\n",
    "merged_data_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/merged_data.csv\"\n",
    "composite_features_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/composite_features.csv\"\n",
    "sub_attribute_weights_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/sub_attribute_weights.csv\"\n",
    "composite_trait_scores_path = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/composite_trait_scores.csv\"\n",
    "\n",
    "# Read the DataFrames from the CSV files\n",
    "merged_data_df = pd.read_csv(merged_data_path)\n",
    "composite_features_df = pd.read_csv(composite_features_path)\n",
    "sub_attribute_weights_df = pd.read_csv(sub_attribute_weights_path)\n",
    "composite_trait_scores_df = pd.read_csv(composite_trait_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9db005c4-62ba-4ed2-8670-65e8ad32da84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified DataFrame:\n",
      "              #AUTHID                                               TEXT  \\\n",
      "0     1997_033283.txt  I don't like having to write an my couch. I ne...   \n",
      "1     1997_053414.txt  This blank screen is staring at me and my fing...   \n",
      "2     1997_057160.txt  I suppose we all get caught up in a web our fi...   \n",
      "3     1997_057748.txt  here I am typing this thing for my psychology ...   \n",
      "4     1997_058607.txt  Ok. Here we go. Well I really don't have much ...   \n",
      "...               ...                                                ...   \n",
      "2458       2004_9.txt  So I'm not sure on what I'm supposed to be typ...   \n",
      "2459      2004_93.txt  my boyfriend is in the room and he stinks like...   \n",
      "2460      2004_94.txt  So this is the third time that I have tried to...   \n",
      "2461      2004_97.txt  I don't know why, but for some reason I am ext...   \n",
      "2462      2004_99.txt  I am currently thinking about how ready I am t...   \n",
      "\n",
      "      cEXT  cNEU  cAGR  cCON  cOPN       mairesse_0  mairesse_1  mairesse_2  \\\n",
      "0        1     0     1     0     1  1997_033283.txt   -0.527438    0.542460   \n",
      "1        1     0     1     1     1  1997_053414.txt    0.122799    0.596609   \n",
      "2        1     0     1     1     1  1997_057160.txt    0.547049    0.592373   \n",
      "3        0     1     0     0     1  1997_057748.txt    0.293964    0.113263   \n",
      "4        0     1     0     0     1  1997_058607.txt    0.622113    0.166377   \n",
      "...    ...   ...   ...   ...   ...              ...         ...         ...   \n",
      "2458     1     0     1     1     0       2004_9.txt   -0.070240   -0.040438   \n",
      "2459     1     1     0     1     1      2004_93.txt    0.514006   -0.607444   \n",
      "2460     0     0     1     1     1      2004_94.txt    1.365228   -1.203851   \n",
      "2461     1     0     1     0     1      2004_97.txt   -1.155525    0.758308   \n",
      "2462     0     1     0     1     0      2004_99.txt   -0.233586    0.464039   \n",
      "\n",
      "      ...  mairesse_75  mairesse_76  mairesse_77  mairesse_78  mairesse_79  \\\n",
      "0     ...    -0.422267    -1.028267    -0.451544    -0.408772    -0.548258   \n",
      "1     ...    -0.422267     0.513222    -0.451544     1.416726     0.420822   \n",
      "2     ...    -0.422267     0.072635    -0.451544    -0.408772     0.696330   \n",
      "3     ...    -0.422267    -0.117985    -0.451544     2.926405     1.379657   \n",
      "4     ...     0.282936     0.395639     1.391566     2.313762     0.626087   \n",
      "...   ...          ...          ...          ...          ...          ...   \n",
      "2458  ...     0.978354     2.079839    -0.451544    -0.408772     1.174987   \n",
      "2459  ...    -0.422267     0.195045     0.418560     0.362388    -0.196020   \n",
      "2460  ...    -0.422267    -0.573506    -0.451544     0.035343     0.198832   \n",
      "2461  ...    -0.422267     1.124512    -0.451544    -0.408772     0.136352   \n",
      "2462  ...    -0.422267    -0.200981    -0.451544    -0.408772    -1.007175   \n",
      "\n",
      "      mairesse_80  mairesse_81  mairesse_82  mairesse_83  mairesse_84  \n",
      "0        4.717551     4.945683     4.712785     4.988888     4.397205  \n",
      "1        4.983241     3.990245     4.710706     4.786429     5.008889  \n",
      "2        5.236637     4.523718     4.785542     4.779305     4.363364  \n",
      "3        4.890906     3.841501     4.662365     4.717712     4.398082  \n",
      "4        4.816808     3.609516     4.530539     4.729812     5.150494  \n",
      "...           ...          ...          ...          ...          ...  \n",
      "2458     5.108716     3.519311     5.069920     5.048177     4.677130  \n",
      "2459     5.050533     3.853904     4.539493     4.865645     4.931603  \n",
      "2460     4.210517     4.036663     4.400920     4.464602     5.021851  \n",
      "2461     5.015506     3.673460     4.953255     4.678684     4.109633  \n",
      "2462     4.601754     3.479341     4.956190     5.115384     4.338944  \n",
      "\n",
      "[2463 rows x 92 columns]\n",
      "Number of unique combinations of 1's and 0's: 32\n"
     ]
    }
   ],
   "source": [
    "# Replace these with the actual column names from your DataFrame\n",
    "columns_to_change = ['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']\n",
    "\n",
    "# Convert 'y' to 1 and 'n' to 0 for only the specified columns\n",
    "merged_data_df[columns_to_change] = merged_data_df[columns_to_change].replace({'y': 1, 'n': 0})\n",
    "\n",
    "# Display the DataFrame to check changes\n",
    "print(\"Modified DataFrame:\")\n",
    "print(merged_data_df)\n",
    "\n",
    "# Extract the columns of interest\n",
    "subset_df = merged_data_df[columns_to_change]\n",
    "\n",
    "# Drop duplicate rows to find unique combinations\n",
    "unique_combinations_df = subset_df.drop_duplicates()\n",
    "\n",
    "# Count the number of unique combinations\n",
    "count_combinations = unique_combinations_df.shape[0]\n",
    "\n",
    "print(f\"Number of unique combinations of 1's and 0's: {count_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a04940d-6968-4b58-8b61-3deafd61945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cEXT  cNEU  cAGR  cCON  cOPN  Sense of coherence  Balance  \\\n",
      "0        1     0     1     0     1             129.850    3.000   \n",
      "1        1     0     1     1     1             177.020    4.000   \n",
      "2        1     0     1     1     1             177.020    4.000   \n",
      "3        0     1     0     0     1             101.740   37.085   \n",
      "4        0     1     0     0     1             101.740   37.085   \n",
      "...    ...   ...   ...   ...   ...                 ...      ...   \n",
      "2458     1     0     1     1     0             133.075    3.000   \n",
      "2459     1     1     0     1     1             200.735   39.085   \n",
      "2460     0     0     1     1     1             125.195    3.000   \n",
      "2461     1     0     1     0     1             129.850    3.000   \n",
      "2462     0     1     0     1     0             104.965   37.085   \n",
      "\n",
      "      Comprehensibility  Manageability  Meaningfulness  Reflection  \n",
      "0                26.950         45.725            3.00        4.50  \n",
      "1                55.655         73.145            4.00       23.96  \n",
      "2                55.655         73.145            4.00       23.96  \n",
      "3                30.090         46.620           41.96       39.07  \n",
      "4                30.090         46.620           41.96       39.07  \n",
      "...                 ...            ...             ...         ...  \n",
      "2458             54.655         71.145            3.00       22.46  \n",
      "2459             83.745         77.770           43.96       60.03  \n",
      "2460             30.705         69.415            3.00       22.46  \n",
      "2461             26.950         45.725            3.00        4.50  \n",
      "2462             57.795         72.040           41.96       57.03  \n",
      "\n",
      "[2463 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming weights is a dictionary of dictionaries,\n",
    "# where the first key is the Psychological Construct,\n",
    "# and the second key is the trait, and the value is the weight\n",
    "weights = {\n",
    "    'Sense of coherence': {'Neuroticism': 57.795, 'Extraversion': 51.825, 'Openness': 43.945, 'Agreeableness': 34.08, 'Conscientiousness': 47.17},\n",
    "    'Balance': {'Neuroticism': 36.085, 'Extraversion': 1.0, 'Openness': 1.0, 'Agreeableness': 1.0, 'Conscientiousness': 1.0},\n",
    "    'Comprehensibility': {'Neuroticism': 29.09, 'Extraversion': 24.95, 'Openness': 1.0, 'Agreeableness': 1.0, 'Conscientiousness': 28.705},\n",
    "    'Manageability': {'Neuroticism': 44.62, 'Extraversion': 3.73, 'Openness': 2.0, 'Agreeableness': 39.995, 'Conscientiousness': 27.42},\n",
    "    'Meaningfulness': {'Neuroticism': 40.96, 'Extraversion': 1.0, 'Openness': 1.0, 'Agreeableness': 1.0, 'Conscientiousness': 1.0},\n",
    "    'Reflection': {'Neuroticism': 37.57, 'Extraversion': 1.5, 'Openness': 1.5, 'Agreeableness': 1.5, 'Conscientiousness': 19.46}\n",
    "}\n",
    "\n",
    "# Map the column names to the trait names\n",
    "column_to_trait = {'cEXT': 'Extraversion', 'cNEU': 'Neuroticism', 'cAGR': 'Agreeableness', 'cCON': 'Conscientiousness', 'cOPN': 'Openness'}\n",
    "\n",
    "def calculate_combinations(row):\n",
    "    combination_results = {}\n",
    "    for construct, traits in weights.items():\n",
    "        weighted_sum = 0\n",
    "        for col, trait in column_to_trait.items():\n",
    "            weighted_sum += row[col] * traits[trait]\n",
    "        combination_results[construct] = weighted_sum\n",
    "    return pd.Series(combination_results)\n",
    "\n",
    "# Assuming merged_data_df is your DataFrame with the traits columns\n",
    "merged_data_df = merged_data_df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN', 'Sense of coherence', 'Balance', 'Comprehensibility', 'Manageability', 'Meaningfulness', 'Reflection']]\n",
    "\n",
    "# Calculate the combination results\n",
    "combination_results = merged_data_df.apply(calculate_combinations, axis=1)\n",
    "\n",
    "# Concatenate the combination results back to the original DataFrame\n",
    "merged_data_df = pd.concat([merged_data_df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']], combination_results], axis=1)\n",
    "\n",
    "print(merged_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80890fec-b634-4912-b1b0-6dbd5cf441fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the result to /home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/merged/merged_data_with_traits.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where you want to save the result\n",
    "output_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/merged\"\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified directory\n",
    "output_file_path = f\"{output_directory}/merged_data_with_traits.csv\"\n",
    "merged_data_with_new_advanced_features_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Saved the result to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53a5e84c-81ce-40fa-8a89-1309e12a7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cEXT  cNEU  cAGR  cCON  cOPN  Sense of coherence  Balance  \\\n",
      "0        1     0     1     0     1             129.850    3.000   \n",
      "1        1     0     1     1     1             177.020    4.000   \n",
      "2        1     0     1     1     1             177.020    4.000   \n",
      "3        0     1     0     0     1             101.740   37.085   \n",
      "4        0     1     0     0     1             101.740   37.085   \n",
      "...    ...   ...   ...   ...   ...                 ...      ...   \n",
      "2458     1     0     1     1     0             133.075    3.000   \n",
      "2459     1     1     0     1     1             200.735   39.085   \n",
      "2460     0     0     1     1     1             125.195    3.000   \n",
      "2461     1     0     1     0     1             129.850    3.000   \n",
      "2462     0     1     0     1     0             104.965   37.085   \n",
      "\n",
      "      Comprehensibility  Manageability  Meaningfulness  ...  \\\n",
      "0                26.950         45.725            3.00  ...   \n",
      "1                55.655         73.145            4.00  ...   \n",
      "2                55.655         73.145            4.00  ...   \n",
      "3                30.090         46.620           41.96  ...   \n",
      "4                30.090         46.620           41.96  ...   \n",
      "...                 ...            ...             ...  ...   \n",
      "2458             54.655         71.145            3.00  ...   \n",
      "2459             83.745         77.770           43.96  ...   \n",
      "2460             30.705         69.415            3.00  ...   \n",
      "2461             26.950         45.725            3.00  ...   \n",
      "2462             57.795         72.040           41.96  ...   \n",
      "\n",
      "      cCON_Comprehensibility_interaction  cCON_Manageability_interaction  \\\n",
      "0                               0.000000                       -0.000000   \n",
      "1                              31.616971                       -5.313032   \n",
      "2                              31.616971                       -5.313032   \n",
      "3                               0.000000                       -0.000000   \n",
      "4                               0.000000                       -0.000000   \n",
      "...                                  ...                             ...   \n",
      "2458                           31.048882                       -5.167758   \n",
      "2459                           47.574579                       -5.648978   \n",
      "2460                           17.443160                       -5.042096   \n",
      "2461                            0.000000                       -0.000000   \n",
      "2462                           32.832680                       -5.232768   \n",
      "\n",
      "      cCON_Meaningfulness_interaction  cCON_Reflection_interaction  \\\n",
      "0                           -0.000000                    -0.000000   \n",
      "1                           -4.739769                   -28.580996   \n",
      "2                           -4.739769                   -28.580996   \n",
      "3                           -0.000000                    -0.000000   \n",
      "4                           -0.000000                    -0.000000   \n",
      "...                               ...                          ...   \n",
      "2458                        -3.554827                   -26.791701   \n",
      "2459                       -52.090059                   -71.607562   \n",
      "2460                        -3.554827                   -26.791701   \n",
      "2461                        -0.000000                    -0.000000   \n",
      "2462                       -49.720175                   -68.028973   \n",
      "\n",
      "      cOPN_Sense of coherence_interaction  cOPN_Balance_interaction  \\\n",
      "0                              217.337977                  0.625775   \n",
      "1                              296.289323                  0.834367   \n",
      "2                              296.289323                  0.834367   \n",
      "3                              170.288531                  7.735622   \n",
      "4                              170.288531                  7.735622   \n",
      "...                                   ...                       ...   \n",
      "2458                             0.000000                  0.000000   \n",
      "2459                           335.982586                  8.152805   \n",
      "2460                           209.546615                  0.625775   \n",
      "2461                           217.337977                  0.625775   \n",
      "2462                             0.000000                  0.000000   \n",
      "\n",
      "      cOPN_Comprehensibility_interaction  cOPN_Manageability_interaction  \\\n",
      "0                              15.309988                       -3.321326   \n",
      "1                              31.616971                       -5.313032   \n",
      "2                              31.616971                       -5.313032   \n",
      "3                              17.093786                       -3.386336   \n",
      "4                              17.093786                       -3.386336   \n",
      "...                                  ...                             ...   \n",
      "2458                            0.000000                       -0.000000   \n",
      "2459                           47.574579                       -5.648978   \n",
      "2460                           17.443160                       -5.042096   \n",
      "2461                           15.309988                       -3.321326   \n",
      "2462                            0.000000                       -0.000000   \n",
      "\n",
      "      cOPN_Meaningfulness_interaction  cOPN_Reflection_interaction  \n",
      "0                           -3.554827                    -5.367883  \n",
      "1                           -4.739769                   -28.580996  \n",
      "2                           -4.739769                   -28.580996  \n",
      "3                          -49.720175                   -46.605155  \n",
      "4                          -49.720175                   -46.605155  \n",
      "...                               ...                          ...  \n",
      "2458                        -0.000000                    -0.000000  \n",
      "2459                       -52.090059                   -71.607562  \n",
      "2460                        -3.554827                   -26.791701  \n",
      "2461                        -3.554827                    -5.367883  \n",
      "2462                        -0.000000                    -0.000000  \n",
      "\n",
      "[2463 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_data_df contains Big5 traits and calculated psychological construct scores\n",
    "# Assuming adjusted_scores_df contains the adjusted scores for each psychological construct\n",
    "\n",
    "# Convert the adjusted_scores_df into a dictionary for easy lookup\n",
    "adjusted_scores_dict = {\n",
    "    'Sense of coherence': 1.6737618528160483,\n",
    "    'Balance': 0.20859166566826876,\n",
    "    'Comprehensibility': 0.5680885917670295,\n",
    "    'Manageability': -0.07263697531591971,\n",
    "    'Meaningfulness': -1.1849422057421488,\n",
    "    'Reflection': -1.1928629291932777\n",
    "}\n",
    "\n",
    "# Function to create new features based on interactions between traits and psychological constructs\n",
    "def create_interaction_features(row):\n",
    "    new_features = {}\n",
    "    for col in column_to_trait.keys():  # Loop through the Big5 trait columns\n",
    "        for construct in adjusted_scores_dict.keys():  # Loop through the psychological constructs\n",
    "            # Create interaction terms\n",
    "            interaction_term = row[col] * row[construct] * adjusted_scores_dict[construct]\n",
    "            new_features[f\"{col}_{construct}_interaction\"] = interaction_term\n",
    "    return pd.Series(new_features)\n",
    "\n",
    "# Apply the function to create new interaction features\n",
    "new_features_df = merged_data_df.apply(create_interaction_features, axis=1)\n",
    "\n",
    "# Concatenate the new features to the original DataFrame\n",
    "merged_data_with_new_features_df = pd.concat([merged_data_df, new_features_df], axis=1)\n",
    "\n",
    "print(merged_data_with_new_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "590ad998-aea6-4b2c-a3ae-40dd9d6bf3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the result to /home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/merged/merged_data_with_traitbig5_interactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where you want to save the result\n",
    "output_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/merged\"\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified directory\n",
    "output_file_path = f\"{output_directory}/merged_data_with_traitbig5_interactions.csv\"\n",
    "merged_data_with_new_features_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Saved the result to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4935842a-67e3-42ce-8094-9ed24ae3b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cEXT  cNEU  cAGR  cCON  cOPN  Sense of coherence  Balance  \\\n",
      "0        1     0     1     0     1             129.850    3.000   \n",
      "1        1     0     1     1     1             177.020    4.000   \n",
      "2        1     0     1     1     1             177.020    4.000   \n",
      "3        0     1     0     0     1             101.740   37.085   \n",
      "4        0     1     0     0     1             101.740   37.085   \n",
      "...    ...   ...   ...   ...   ...                 ...      ...   \n",
      "2458     1     0     1     1     0             133.075    3.000   \n",
      "2459     1     1     0     1     1             200.735   39.085   \n",
      "2460     0     0     1     1     1             125.195    3.000   \n",
      "2461     1     0     1     0     1             129.850    3.000   \n",
      "2462     0     1     0     1     0             104.965   37.085   \n",
      "\n",
      "      Comprehensibility  Manageability  Meaningfulness  ...  \\\n",
      "0                26.950         45.725            3.00  ...   \n",
      "1                55.655         73.145            4.00  ...   \n",
      "2                55.655         73.145            4.00  ...   \n",
      "3                30.090         46.620           41.96  ...   \n",
      "4                30.090         46.620           41.96  ...   \n",
      "...                 ...            ...             ...  ...   \n",
      "2458             54.655         71.145            3.00  ...   \n",
      "2459             83.745         77.770           43.96  ...   \n",
      "2460             30.705         69.415            3.00  ...   \n",
      "2461             26.950         45.725            3.00  ...   \n",
      "2462             57.795         72.040           41.96  ...   \n",
      "\n",
      "      cCON_Comprehensibility_advanced_interaction  \\\n",
      "0                                        0.000000   \n",
      "1                                       23.653375   \n",
      "2                                       23.653375   \n",
      "3                                        0.000000   \n",
      "4                                        0.000000   \n",
      "...                                           ...   \n",
      "2458                                    23.228375   \n",
      "2459                                    35.591625   \n",
      "2460                                    13.049625   \n",
      "2461                                     0.000000   \n",
      "2462                                    24.562875   \n",
      "\n",
      "      cCON_Manageability_advanced_interaction  \\\n",
      "0                                    0.000000   \n",
      "1                                   19.383425   \n",
      "2                                   19.383425   \n",
      "3                                    0.000000   \n",
      "4                                    0.000000   \n",
      "...                                       ...   \n",
      "2458                                18.853425   \n",
      "2459                                20.609050   \n",
      "2460                                18.394975   \n",
      "2461                                 0.000000   \n",
      "2462                                19.090600   \n",
      "\n",
      "      cCON_Meaningfulness_advanced_interaction  \\\n",
      "0                                        0.000   \n",
      "1                                        1.700   \n",
      "2                                        1.700   \n",
      "3                                        0.000   \n",
      "4                                        0.000   \n",
      "...                                        ...   \n",
      "2458                                     1.275   \n",
      "2459                                    18.683   \n",
      "2460                                     1.275   \n",
      "2461                                     0.000   \n",
      "2462                                    17.833   \n",
      "\n",
      "      cCON_Reflection_advanced_interaction  \\\n",
      "0                                  0.00000   \n",
      "1                                 12.09980   \n",
      "2                                 12.09980   \n",
      "3                                  0.00000   \n",
      "4                                  0.00000   \n",
      "...                                    ...   \n",
      "2458                              11.34230   \n",
      "2459                              30.31515   \n",
      "2460                              11.34230   \n",
      "2461                               0.00000   \n",
      "2462                              28.80015   \n",
      "\n",
      "      cOPN_Sense of coherence_advanced_interaction  \\\n",
      "0                                           25.970   \n",
      "1                                           35.404   \n",
      "2                                           35.404   \n",
      "3                                           20.348   \n",
      "4                                           20.348   \n",
      "...                                            ...   \n",
      "2458                                         0.000   \n",
      "2459                                        40.147   \n",
      "2460                                        25.039   \n",
      "2461                                        25.970   \n",
      "2462                                         0.000   \n",
      "\n",
      "      cOPN_Balance_advanced_interaction  \\\n",
      "0                              0.315000   \n",
      "1                              0.420000   \n",
      "2                              0.420000   \n",
      "3                              3.893925   \n",
      "4                              3.893925   \n",
      "...                                 ...   \n",
      "2458                           0.000000   \n",
      "2459                           4.103925   \n",
      "2460                           0.315000   \n",
      "2461                           0.315000   \n",
      "2462                           0.000000   \n",
      "\n",
      "      cOPN_Comprehensibility_advanced_interaction  \\\n",
      "0                                        9.297750   \n",
      "1                                       19.200975   \n",
      "2                                       19.200975   \n",
      "3                                       10.381050   \n",
      "4                                       10.381050   \n",
      "...                                           ...   \n",
      "2458                                     0.000000   \n",
      "2459                                    28.892025   \n",
      "2460                                    10.593225   \n",
      "2461                                     9.297750   \n",
      "2462                                     0.000000   \n",
      "\n",
      "      cOPN_Manageability_advanced_interaction  \\\n",
      "0                                   12.574375   \n",
      "1                                   20.114875   \n",
      "2                                   20.114875   \n",
      "3                                   12.820500   \n",
      "4                                   12.820500   \n",
      "...                                       ...   \n",
      "2458                                 0.000000   \n",
      "2459                                21.386750   \n",
      "2460                                19.089125   \n",
      "2461                                12.574375   \n",
      "2462                                 0.000000   \n",
      "\n",
      "      cOPN_Meaningfulness_advanced_interaction  \\\n",
      "0                                       1.3800   \n",
      "1                                       1.8400   \n",
      "2                                       1.8400   \n",
      "3                                      19.3016   \n",
      "4                                      19.3016   \n",
      "...                                        ...   \n",
      "2458                                    0.0000   \n",
      "2459                                   20.2216   \n",
      "2460                                    1.3800   \n",
      "2461                                    1.3800   \n",
      "2462                                    0.0000   \n",
      "\n",
      "      cOPN_Reflection_advanced_interaction  \n",
      "0                                   3.0150  \n",
      "1                                  16.0532  \n",
      "2                                  16.0532  \n",
      "3                                  26.1769  \n",
      "4                                  26.1769  \n",
      "...                                    ...  \n",
      "2458                                0.0000  \n",
      "2459                               40.2201  \n",
      "2460                               15.0482  \n",
      "2461                                3.0150  \n",
      "2462                                0.0000  \n",
      "\n",
      "[2463 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already read the DataFrame\n",
    "composite_trait_scores_df = pd.read_csv('/home/vincent/AAA_projects/MVCS/DigitalHuman/data/composite_features.csv')\n",
    "\n",
    "# Create the composite_feature_dict from the DataFrame\n",
    "composite_feature_dict = {}\n",
    "for index, row in composite_trait_scores_df.iterrows():\n",
    "    construct = row['Psychological Construct']\n",
    "    trait = row['Researched Trait']\n",
    "    composite_feature = row['Composite Feature']\n",
    "    \n",
    "    if construct not in composite_feature_dict:\n",
    "        composite_feature_dict[construct] = {}\n",
    "    \n",
    "    composite_feature_dict[construct][trait] = composite_feature\n",
    "\n",
    "# Function to create new features\n",
    "def create_advanced_interaction_features(row):\n",
    "    new_features = {}\n",
    "    for col in column_to_trait.keys():  # Assuming column_to_trait is a mapping from your columns to Big5 traits\n",
    "        for construct in composite_feature_dict.keys():  # Loop through the psychological constructs\n",
    "            # Retrieve the corresponding Composite Feature value\n",
    "            composite_value = composite_feature_dict[construct].get(column_to_trait[col], 0)\n",
    "            \n",
    "            # Create new interaction terms\n",
    "            interaction_term = row[col] * row[construct] * composite_value\n",
    "            new_features[f\"{col}_{construct}_advanced_interaction\"] = interaction_term\n",
    "    return pd.Series(new_features)\n",
    "\n",
    "# Assuming merged_data_df contains your original data\n",
    "# Apply the function to create new advanced interaction features\n",
    "new_advanced_features_df = merged_data_df.apply(create_advanced_interaction_features, axis=1)\n",
    "\n",
    "# Concatenate the new features to the original DataFrame\n",
    "merged_data_with_new_advanced_features_df = pd.concat([merged_data_df, new_advanced_features_df], axis=1)\n",
    "\n",
    "print(merged_data_with_new_advanced_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d2f03a7-7330-43b9-a110-44de815de4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the result to /home/vincent/AAA_projects/University/MSc_AI/Big Data Analysis/project2data/personality-prediction-from-text/data/training/merged/completed/merged_data_with_advanced_interactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where you want to save the result\n",
    "output_directory = \"/home/vincent/AAA_projects/MVCS/DigitalHuman/data/merged/completed\"\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified directory\n",
    "output_file_path = f\"{output_directory}/merged_data_with_advanced_interactions.csv\"\n",
    "merged_data_with_new_advanced_features_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Saved the result to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af25b4-3b45-4248-8506-e5c000e5c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a70b21-52e2-4a74-a2f8-5ec834f15d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b787e29a-be5d-4fd3-a298-206cfb9bc8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged_data_df: (2463, 92)\n",
      "Shape of composite_features_df: (30, 7)\n",
      "Shape of sub_attribute_weights_df: (30, 3)\n",
      "Shape of composite_trait_scores_df: (6, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape (rows and columns) of each DataFrame\n",
    "print(f\"Shape of merged_data_df: {merged_data_df.shape}\")\n",
    "print(f\"Shape of composite_features_df: {composite_features_df.shape}\")\n",
    "print(f\"Shape of sub_attribute_weights_df: {sub_attribute_weights_df.shape}\")\n",
    "print(f\"Shape of composite_trait_scores_df: {composite_trait_scores_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92af6ade-5e5b-4290-b7d1-17d7ac61b5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows of merged_data_df:\n",
      "           #AUTHID                                               TEXT cEXT  \\\n",
      "0  1997_033283.txt  I don't like having to write an my couch. I ne...    y   \n",
      "1  1997_053414.txt  This blank screen is staring at me and my fing...    y   \n",
      "\n",
      "  cNEU cAGR cCON cOPN       mairesse_0  mairesse_1  mairesse_2  ...  \\\n",
      "0    n    y    n    y  1997_033283.txt   -0.527438    0.542460  ...   \n",
      "1    n    y    y    y  1997_053414.txt    0.122799    0.596609  ...   \n",
      "\n",
      "   mairesse_75  mairesse_76  mairesse_77  mairesse_78  mairesse_79  \\\n",
      "0    -0.422267    -1.028267    -0.451544    -0.408772    -0.548258   \n",
      "1    -0.422267     0.513222    -0.451544     1.416726     0.420822   \n",
      "\n",
      "   mairesse_80  mairesse_81  mairesse_82  mairesse_83  mairesse_84  \n",
      "0     4.717551     4.945683     4.712785     4.988888     4.397205  \n",
      "1     4.983241     3.990245     4.710706     4.786429     5.008889  \n",
      "\n",
      "[2 rows x 92 columns]\n",
      "\n",
      "First two rows of composite_features_df:\n",
      "  Psychological Construct Researched Trait  Composite Feature   k       Q  \\\n",
      "0      Sense of coherence      Neuroticism             -0.905  21  369.75   \n",
      "1      Sense of coherence     Extraversion              0.410  17  119.87   \n",
      "\n",
      "      I2    τ2  \n",
      "0  94.59  0.03  \n",
      "1  86.65  0.01  \n",
      "\n",
      "First two rows of sub_attribute_weights_df:\n",
      "  Psychological Construct Researched Trait  Sub-Attribute Weight\n",
      "0      Sense of coherence      Neuroticism                57.795\n",
      "1      Sense of coherence     Extraversion                51.825\n",
      "\n",
      "First two rows of composite_trait_scores_df:\n",
      "  Psychological Construct  Composite-Trait Score\n",
      "0      Sense of coherence              14.792925\n",
      "1                 Balance              -3.113075\n"
     ]
    }
   ],
   "source": [
    "# Print the first two rows of each DataFrame\n",
    "print(\"First two rows of merged_data_df:\")\n",
    "print(merged_data_df.head(2))\n",
    "\n",
    "print(\"\\nFirst two rows of composite_features_df:\")\n",
    "print(composite_features_df.head(2))\n",
    "\n",
    "print(\"\\nFirst two rows of sub_attribute_weights_df:\")\n",
    "print(sub_attribute_weights_df.head(2))\n",
    "\n",
    "print(\"\\nFirst two rows of composite_trait_scores_df:\")\n",
    "print(composite_trait_scores_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc8800-54db-4b99-bf89-a316076250fd",
   "metadata": {},
   "source": [
    "# Probability scores for traits for Sense of coherence, Balance, Comprehensibility, Manageability, Meaningfulness, Reflection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba405ec-2eef-48c8-9c12-0ebd3ffff123",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAA_projects/MVCS/DigitalHuman/data/sub_attribute_weights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m merged_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAA_projects/MVCS/DigitalHuman/data/merged/completed/merged_data_with_advanced_interactions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Importing CSV files into pandas DataFrames\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m sub_attr_weights_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_attr_weights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m psych_traits_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(psych_traits_path)\n\u001b[1;32m     13\u001b[0m composite_trait_scores_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(composite_trait_scores_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAA_projects/MVCS/DigitalHuman/data/sub_attribute_weights.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "sub_attr_weights_path = \"AAA_projects/MVCS/DigitalHuman/data/sub_attribute_weights.csv\"\n",
    "psych_traits_path = \"AAA_projects/MVCS/DigitalHuman/data/psych_traits_digital_human_dict.csv\"\n",
    "composite_trait_scores_path = \"AAA_projects/MVCS/DigitalHuman/data/composite_trait_scores.csv\"\n",
    "adjusted_scores_path = \"AAA_projects/MVCS/DigitalHuman/data/adjusted_scores.csv\"\n",
    "merged_data_path = \"AAA_projects/MVCS/DigitalHuman/data/merged/completed/merged_data_with_advanced_interactions.csv\"\n",
    "\n",
    "# Importing CSV files into pandas DataFrames\n",
    "sub_attr_weights_df = pd.read_csv(sub_attr_weights_path)\n",
    "psych_traits_df = pd.read_csv(psych_traits_path)\n",
    "composite_trait_scores_df = pd.read_csv(composite_trait_scores_path)\n",
    "adjusted_scores_df = pd.read_csv(adjusted_scores_path)\n",
    "merged_data_df = pd.read_csv(merged_data_path)\n",
    "\n",
    "# Converting the DataFrames to dictionaries if needed (depends on your file format)\n",
    "# Here we assume the column names in CSV align with trait names and sub-attribute names\n",
    "sub_attr_weights_dict = sub_attr_weights_df.set_index('construct').to_dict(orient='index')\n",
    "correlations_dict = composite_trait_scores_df.set_index('construct').to_dict(orient='index')\n",
    "\n",
    "def calculate_scores(row_data, sub_attr_weights_dict, correlations_dict):\n",
    "    calculated_scores = {}\n",
    "    \n",
    "    for construct, traits in sub_attr_weights_dict.items():\n",
    "        score = 0\n",
    "        for trait, weight in traits.items():\n",
    "            score += row_data[trait] * weight * correlations_dict[construct][trait]\n",
    "        calculated_scores[construct] = score\n",
    "    \n",
    "    return calculated_scores\n",
    "\n",
    "# Assuming that merged_data_df contains rows with trait data, apply calculate_scores function row-wise\n",
    "# This will add a new column 'calculated_scores' containing the calculated scores for each row\n",
    "merged_data_df['calculated_scores'] = merged_data_df.apply(lambda row: calculate_scores(row, sub_attr_weights_dict, correlations_dict), axis=1)\n",
    "\n",
    "print(merged_data_df['calculated_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033e549-868f-41e2-8f39-d5234c2a0460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47df16-d067-4024-af81-08999275d030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e4174-0946-4678-b279-90765c73c89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe56dc0-a1d7-4440-8e0b-fca3b1e7cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://link.springer.com/article/10.1007/s12144-022-03944-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd99d5-a5e0-49c1-81ec-28ee989010fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.sciencedirect.com/science/article/abs/pii/S0191886918300576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dbc71-2ba0-4f47-8805-87d59ba8cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23dde16-fdc5-4b27-84d8-ffa1ba9ff66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba3532-b9d8-41a7-93bb-d3c0f96f94a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab2efdb-f3ab-41ae-a503-426612ce3347",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b88bbc-ebd2-402d-9e89-ba4dcebcc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bag-of-Words (BoW)\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Word Embeddings\n",
    "BERT or other Transformer Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab15e9-9df2-4239-a985-1de816776250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb29ae0c-2cbe-42a8-b5c3-876caad203b6",
   "metadata": {},
   "source": [
    "# Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6e312-087b-4099-af44-90e3ba5c1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC (Linguistic Inquiry and Word Count):\n",
    "AFINN\n",
    "NRC Emotion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a5387-409c-417a-ba4a-1bcb23c6236d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561579c-ea86-4b26-aec1-d9da6f6ba442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47b6386-f722-476f-90a9-ba78dd3692f8",
   "metadata": {},
   "source": [
    "# concatenate Vectorization and Lexicons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9cbd84-5d7f-4d90-ae3f-3496fe6dff67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5c56d-d521-4298-b464-929cc318172a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367041aa-35e6-42e9-a878-557c18509007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa37c8-d91c-4a3d-9373-6a42765c3762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1b031-74c3-4204-8195-77a19e4c68f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
